<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Événements | GdR IG-RV</title><link>https://gdr-igrv.fr/event/</link><atom:link href="https://gdr-igrv.fr/event/index.xml" rel="self" type="application/rss+xml"/><description>Événements</description><generator>Wowchemy (https://wowchemy.com)</generator><language>fr-fr</language><image><url>https://gdr-igrv.fr/media/icon_hu6ab350bd9da14bf3d770a252e9dc8f37_21017_512x512_fill_lanczos_center_3.png</url><title>Événements</title><link>https://gdr-igrv.fr/event/</link></image><item><title>24èmes journées du Groupe de Travail Animation et Simulation</title><link>https://gdr-igrv.fr/event/journee_gtas2022/</link><pubDate>Tue, 05 Jul 2022 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee_gtas2022/</guid><description>&lt;p>Les prochaines journées du Groupe de Travail Animation et Simulation du GDR IGRV auront lieu du mardi 5 juillet 2022 au mercredi 6 juillet 2022, à Vannes, sur le campus de Tohannic, bâtiment ENSIBS.&lt;/p>
&lt;p>L’objet des Journées du GT AS est triple. Il s’agit :&lt;/p>
&lt;ul>
&lt;li>de partager les avancées de la recherche en animation et simulation,&lt;/li>
&lt;li>de dresser le paysage du domaine en France, et&lt;/li>
&lt;li>d’en préciser les perspectives et les thématiques émergentes.&lt;/li>
&lt;/ul>
&lt;p>Cette année, plusieurs présentations de &lt;strong>travaux et résultats récents&lt;/strong> aborderont des thèmes diversifiés tels que l&amp;rsquo;analyse, la synthèse et l&amp;rsquo;édition de mouvement, la modélisation et la simulation de phénomènes naturels, la capture de mouvements faciaux et du regard, la modélisation et l&amp;rsquo;animation faciale, la synthèse de gestes liés à la prosodie, les aspects multimodaux et multisensoriels dans l&amp;rsquo;animation, l&amp;rsquo;évolution des techniques de motion capture par vidéo, ou encore la synthèse de mouvements de langue des signes.&lt;/p>
&lt;p>Avec un &lt;strong>spectre plus large&lt;/strong>, plusieurs équipes présenteront un panorama pluriannuel de leur thématiques de recherche et de leurs évolutions, ainsi que des avancées de projets collaboratifs auxquelles elles contribuent.&lt;/p>
&lt;p>Les Journées sont également bien sûr l’occasion d’&lt;strong>échanges et de débats scientifiques&lt;/strong>. Deux thèmes focus ont été retenus pour cette année :&lt;/p>
&lt;ul>
&lt;li>les liens de plus en plus importants, en recherche, qui se construisent entre les technologies de l’intelligence artificielle et les problématiques de l’animation et de la simulation,&lt;/li>
&lt;li>les questions relatives à l’enseignement de l’animation et de la simulation et l’usage de l’AS pour la pédagogie d’autres disciplines.&lt;/li>
&lt;/ul>
&lt;p>Par ailleurs, un &lt;strong>atelier pratique&lt;/strong> sur les technologies de capture du mouvement et leurs usages sera proposé par l’équipe organisatrice Expression, et un moment sera dédié au &lt;strong>partage de réalisations et perspectives artistiques&lt;/strong> (œuvres, projets ou travaux en cours), les processus créatifs étant importants pour notre domaine qui adresse la perception visuelle, notamment dans les aspects dynamiques.&lt;/p>
&lt;p>Enfin, l’ensemble des participants s’attacheront à mettre à jour les éléments prospectifs du domaine : nouveaux sujets, thèmes émergents, perspectives, points clés.&lt;/p>
&lt;p>L’inscription aux Journées est gratuite mais obligatoire – merci de prendre contact avec les coordinateurs du GT pour obtenir le lien d&amp;rsquo;inscription.&lt;/p>
&lt;h2 id="programme-prévisionnel">Programme Prévisionnel&lt;/h2>
&lt;h3 id="mardi-5-juillet-2022">Mardi 5 juillet 2022&lt;/h3>
&lt;p>9h - 12h : Atelier Mocap, animé par l&amp;rsquo;équipe Expression&lt;/p>
&lt;p>12h - 14h : Repas&lt;/p>
&lt;p>14h - 15h30 : Présentations - session 1&lt;/p>
&lt;p>15h30 - 15h45 : Pause café&lt;/p>
&lt;p>15h45 - 17h : Présentations - session 2&lt;/p>
&lt;p>17h : Moment artistique et social event&lt;/p>
&lt;h3 id="mercredi-6-juillet-2022">Mercredi 6 juillet 2022&lt;/h3>
&lt;p>9h : Accueil, hall du batiment ENSIBS&lt;/p>
&lt;p>9h25 - 10h25 : Keynote Christian Theobalt (MaxPlanck Institut)&lt;/p>
&lt;p>&lt;em>Title:&lt;/em> Capturing the Real World in Motion: New ways to unite graphics, vision and machine learning
Abstract: In this presentation, I will talk about some of the recent work we did on new methods for reconstructing computer graphics models of real world scenes from sparse or even monocular video data. These methods are based on bringing together neural network-based and explicit model-based approaches. I will also talk about new neural rendering approaches that combine explicit model-based and neural network based concepts for image formation in new ways. They enable new means to synthesize highly realistic imagery and videos of real work scenes under user control.&lt;/p>
&lt;p>10h30 - 10h45 : Pause café hall ENSIBS&lt;/p>
&lt;p>10h45 - 12h : Présentations - session 3 - focus IA&lt;/p>
&lt;p>12h - 12h30 : Discussions &amp;ldquo;IA et Animation&amp;rdquo;&lt;/p>
&lt;p>12h30 - 13h30 : Repas&lt;/p>
&lt;p>14h - 15h : Discussions &amp;ldquo;Enseignement de l&amp;rsquo;AS et avec l&amp;rsquo;AS&amp;rdquo;&lt;/p>
&lt;p>15h - 15h15 Pause cafe&lt;/p>
&lt;p>15h15 - 16h : Présentations - session 4&lt;/p>
&lt;p>16h - 17h : Discussions &amp;ldquo;Prospectives&amp;rdquo;&lt;/p>
&lt;p>17h : Fin des journées&lt;/p></description></item><item><title>Journées optimisation topologique</title><link>https://gdr-igrv.fr/event/journee_jot2022/</link><pubDate>Thu, 30 Jun 2022 10:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee_jot2022/</guid><description/></item><item><title>Journée Visu 2022</title><link>https://gdr-igrv.fr/event/journee_gtvisu2022/</link><pubDate>Tue, 28 Jun 2022 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee_gtvisu2022/</guid><description/></item><item><title>Journée GT Rendu 2022</title><link>https://gdr-igrv.fr/event/journee_gtrendu2022/</link><pubDate>Mon, 23 May 2022 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee_gtrendu2022/</guid><description/></item><item><title>Journées du GTMG</title><link>https://gdr-igrv.fr/event/journee_gtmg2022/</link><pubDate>Wed, 16 Mar 2022 11:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee_gtmg2022/</guid><description/></item><item><title>Journées Informatique et Géométrie 2022</title><link>https://gdr-igrv.fr/event/jig2022/</link><pubDate>Tue, 15 Mar 2022 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/jig2022/</guid><description/></item><item><title>Journée « Environnements virtuels : adaptation du système à l'humain ou de l'humain au système ? »</title><link>https://gdr-igrv.fr/event/journee_gtrv2022/</link><pubDate>Wed, 09 Mar 2022 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee_gtrv2022/</guid><description>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://journee-rvia.hds.utc.fr/_detail/pma_equipe_copyright.jpg?id=fr%3Astart" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h1 id="responsables">Responsables&lt;/h1>
&lt;ul>
&lt;li>Domitile Lourdeaux (Heudiasyc – Université de technologie de Compiègne)&lt;/li>
&lt;li>Indira Thouvenin-Moutapa (Heudiasyc – Université de technologie de Compiègne)&lt;/li>
&lt;/ul>
&lt;h1 id="programme">Programme&lt;/h1>
&lt;p>&lt;strong>9 mars 2022&lt;/strong>&lt;/p>
&lt;p>Le programme prévisionnel de la journée est le suivant :&lt;/p>
&lt;p>Train de Paris : départ 8.34 - arrivée 9.26 Comptez 10 min pour rejoindre le centre d’innovation en taxi. Les bus sont gratuits mais lents (prévoir 30 min). Voir plan d&amp;rsquo;accès Centre d&amp;rsquo;Innovation à côté du Génie Informatique.&lt;/p>
&lt;p>Le programme sera détaillé ultérieurement, voici les grands temps forts :&lt;/p>
&lt;ul>
&lt;li>9.30-10.00 Accueil, café&lt;/li>
&lt;li>10.10-10.15 Ouverture (Mot de l’AFIA, du GdR IG-RV et de Philippe Bonnifait, directeur de l&amp;rsquo;UMR 7253 Heudiasyc)&lt;/li>
&lt;li>10.15-10.35 « Pourquoi cette journée ? Environnements virtuels : adaptation du système à l&amp;rsquo;humain ou de l&amp;rsquo;humain au système ? » Domitile Lourdeaux et Indira Thouvenin&lt;/li>
&lt;li>10.35-11.05 Présentation invitée « Environnements virtuels et modèles de décision pour l’interaction » IRISA, Rennes&lt;/li>
&lt;li>11.05-11.15 Pause café&lt;/li>
&lt;li>11.15-11.45 Présentation invitée « La réalité virtuelle en tant qu&amp;rsquo;outil de formation adapté aux pratiques de l&amp;rsquo;enseignant: scénarisation des travaux pratiques, enseignement du geste et adaptation au comportement » Ludovic Hamon, LIUM, Laval&lt;/li>
&lt;li>11.45-12.10 « Facteurs humains et réalité virtuelle : détecter les effets secondaires avec capteurs physiologiques et machine learning » Alexis Souchet, Heudiasyc Compiègne&lt;/li>
&lt;li>12.10-12.30 « Génération d’un profil dynamique du stress pour l’entraînement à la gestion de situations de crise » Luca Pelissero-Witoslawski, Heudiasyc Compiègne&lt;/li>
&lt;li>12.30-14.00 Buffet et session Posters&lt;/li>
&lt;li>14.00-15.00 Visite du CAVE et des démonstrations&lt;/li>
&lt;li>15.00-15.30 Présentation invitée « Les agents virtuels dans les environnements immersifs d&amp;rsquo;apprentissage » David Panzoli, IRIT Toulouse&lt;/li>
&lt;li>15.30-15.55 « Toucher social pour l’interaction humain-agent incarné en environnement virtuel » Fabien Boucaud, ISIR, Paris&lt;/li>
&lt;li>15.55-16.15 « Retours adaptatif en réalité augmentée basés sur l’état du conducteur de véhicule hautement automatisé lors de la reprise de contrôle » Baptiste Wojtkowski, Heudiasyc, Compiègne&lt;/li>
&lt;li>16.15-17.00 Table Ronde « Environnements virtuels : adaptation du système à l&amp;rsquo;humain ou de l&amp;rsquo;humain au système ? »&lt;/li>
&lt;/ul>
&lt;p>Un mode hybride est en cours d&amp;rsquo;études mais on privilégie le présentiel pour permettre de participer aux démonstrations.&lt;/p>
&lt;p>Train retour départ 17.35 – arrivée 18.26&lt;/p>
&lt;h1 id="inscriptions">Inscriptions&lt;/h1>
&lt;p>Pour des raisons pratiques, les inscriptions devront se faire avant le 28 février 2022&lt;/p>
&lt;p>&lt;a href="https://journee-rvia.hds.utc.fr/fr/inscriptions" target="_blank" rel="noopener">https://journee-rvia.hds.utc.fr/fr/inscriptions&lt;/a>&lt;/p>
&lt;p>Retrouvez toutes les informations&lt;/p>
&lt;p>&lt;a href="https://journee-rvia.hds.utc.fr/fr/presentation" target="_blank" rel="noopener">https://journee-rvia.hds.utc.fr/fr/presentation&lt;/a>&lt;/p></description></item><item><title>Journée du GT-RV</title><link>https://gdr-igrv.fr/event/journee_gtrv2022-8-03/</link><pubDate>Tue, 08 Mar 2022 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee_gtrv2022-8-03/</guid><description>&lt;p>Comme vous le savez déjà, la journée du GT-RV se tiendra le 8 mars dans les locaux parisiens de l&amp;rsquo;UTC au 62 Boulevard de Sébastopol, 75003 Paris&lt;/p>
&lt;p>Nous vous proposons de vous inscrire à l&amp;rsquo;adresse suivante en indiquant si vous souhaitez être en présentiel ou éventuellement distanciel.
&lt;a href="https://framaforms.org/inscription-journees-du-gt-rv-1644410184" target="_blank" rel="noopener">https://framaforms.org/inscription-journees-du-gt-rv-1644410184&lt;/a>&lt;/p>
&lt;p>L&amp;rsquo;entrée est gratuite, mais le présentiel est limité à 40 personnes.&lt;/p>
&lt;p>Attention, pour des raisons sanitaires, nous ne pouvons pas vous proposer de repas de déjeuner sur place, mais nous avons le plaisir d&amp;rsquo;être accueillis dans un des quartiers parisiens les plus fournis en petits restaurants très sympathiques.&lt;/p>
&lt;p>Le distanciel se fera à cette adresse :
&lt;a href="https://catalogue-ent2.univ-paris8.fr/BigBlueButtonReunion/client.php?meetingID=4882&amp;amp;fullName=Anonyme&amp;amp;password=4bsexESkl7D092oXV_v5jRQKHh6imPyZMpwa&amp;amp;checksum=b1e8eb8c7ad246eb8689dc2f89ed2fb0ecb063bc" target="_blank" rel="noopener">https://catalogue-ent2.univ-paris8.fr/BigBlueButtonReunion/client.php?meetingID=4882&amp;fullName=Anonyme&amp;password=4bsexESkl7D092oXV_v5jRQKHh6imPyZMpwa&amp;checksum=b1e8eb8c7ad246eb8689dc2f89ed2fb0ecb063bc&lt;/a>&lt;/p>
&lt;h1 id="programme">Programme&lt;/h1>
&lt;p>Nous sommes heureux de vous proposer le programme de la journée, que vous pourrez retrouver, pour plus de facilité en pdf attaché en pièce jointe :
9h30-11h00 : Présentations, Chairman : Pr Daniel Mestre&lt;/p>
&lt;ul>
&lt;li>9h 30: &lt;strong>RAMOUSSE Florian&lt;/strong>
Laboratoire / Institution : LIRIS / École Centrale de Lyon&lt;/li>
&lt;/ul>
&lt;p>Titre de la présentation : Immersive environnements for Assessing and Treating Binge Eating Disorders : How the Visual Quality of 3D Food Stimuli can Influence the Desire to Eat&lt;/p>
&lt;ul>
&lt;li>9h50 : &lt;strong>VILLENAVE Sophie&lt;/strong>
Laboratoire / Institution : LIRIS / École Centrale de Lyon-ENISE&lt;/li>
&lt;/ul>
&lt;p>Titre de la présentation : XREcho : Un outil d’enregistrement et de visualisation des expériences XR
Résumé : XREcho, c&amp;rsquo;est un plugin pour le logiciel Unity qui permet d&amp;rsquo;enregistrer et de rejouer en temps réel des sessions d&amp;rsquo;XR (VR et AR), développées avec Unity.
Le développement du plugin est en cours, mais nous sommes en train de rédiger un papier destiné à MMSys pour la section demo/soft/dataset afin d&amp;rsquo;avoir accès à une plateforme de diffusion large.
Ce plugin devrait permettre à la communauté scientifique étudiant le comportement et les interactions des utilisateurs avec l&amp;rsquo;AR et la VR d&amp;rsquo;obtenir des données objectives afin d&amp;rsquo;établir des modèles plus justes et plus proche de la réalité.&lt;/p>
&lt;ul>
&lt;li>10h10 : &lt;strong>Elodie Bayle&lt;/strong>
Laboratoire : Institut de recherche biomédicale des armées&lt;/li>
&lt;/ul>
&lt;p>Titre de la présentation : Entre fusion et rivalité binoculaires : Impact des caractéristiques des stimuli visuels lors de l’utilisation d’un système de réalité augmentée semi-transparent monoculaire.
Résumé : Les visuels de casque monoculaires utilisés dans l’aéronautique augmentent la vision des pilotes et facilitent l’accès aux informations essentielles telles que la symbologie de vol. Du fait de la projection d’une image virtuelle devant un seul œil alors que l’environnement est binoculaire, cela génère une perception visuelle particulière. Le travail de cette thèse consistait à évaluer l’impact des caractéristiques des stimuli sur les performances à travers deux études psychophysiques et une étude écologique en simulateur de vol.&lt;/p>
&lt;ul>
&lt;li>10h30 : &lt;strong>Olivier ROUPIN&lt;/strong>
Laboratoire : Lab-STICC / InterDigital &amp;amp; IMT Atlantique Brest&lt;/li>
&lt;/ul>
&lt;p>Titre de la présentation : Détection d’objets supprimés dans des scènes 3D à l&amp;rsquo;aide d&amp;rsquo;images dans les applications de Réalité Mixte
Résumé : Une connaissance précise de l&amp;rsquo;environnement est requise pour l&amp;rsquo;interaction entre contenu virtuel et réel en réalité mixte. Cependant, une mise à jour en temps réel du modèle de la réalité est coûteuse en temps et matériel; diverses approches hybrides ont donc été développées : un modèle à jour du monde peut être déduit d&amp;rsquo;une capture hors-ligne de l&amp;rsquo;environnement 3D, corrigé en ligne en utilisant une séquence d&amp;rsquo;images courantes, à condition qu&amp;rsquo;un algorithme de détection de changement rapide et robuste soit développé. Les algorithmes existant présente un biais vers la détection d&amp;rsquo;apparition d&amp;rsquo;objets au mépris de la suppression d&amp;rsquo;objets; dans un environnement où l&amp;rsquo;arrière plan est photométriquement uniforme, la disparition d&amp;rsquo;objets au premier plan, entre un scan 3D d&amp;rsquo;une scène et la prise de nouvelles photos de cette même scène, est difficile à détecter par re-projection. Notre approche contourne ce problème en se concentrant sur les régions occultées par le premier plan où aucun changement ne se produit après re-projection. On montre par l&amp;rsquo;expérience sur des dataset réalistes, que cette approche est meilleure à la tâche de détection et localisation 3D d&amp;rsquo;objets supprimés. Cette approche peut être combinée avec un algorithme de détection d&amp;rsquo;apparitions d&amp;rsquo;objets pour produire un système de détection de changement complet.&lt;/p>
&lt;ul>
&lt;li>10h50 : &lt;strong>Charlotte DUBOSC&lt;/strong>
Laboratoire : Présence &amp;amp; Innovation, LAMPA / ENSAM Laval&lt;/li>
&lt;/ul>
&lt;p>Titre de la présentation : Étude de l’interdépendance du réalisme visuel et comportemental pour l’acceptation des personnages virtuels en environnement immersif collaboratif
Résumé : Présentation du protocole et des développements d’une expérimentation de thèse portant sur l’interdépendance du réalisme visuel et comportemental de personnages virtuels. Cette étude ambitionne d’évaluer la tolérance des utilisateurs confrontés à des personnages dont l’apparence présente des inadéquations potentielles avec leur expressivité faciale. Les évaluations porteront sur le réalisme perçu, la familiarité, l’étrangeté et l’attractivité des agents virtuels.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>11h10-11h30 pause&lt;/p>
&lt;/li>
&lt;li>
&lt;p>11h30-12h30 : &lt;strong>Présentations&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>11h30 : &lt;strong>Rebecca Fribourg&lt;/strong> (École Centrale de Nantes) — Prix de thèse IG-RV 2021&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Titre de la présentation : &amp;ldquo;Contribution to the study of factors influencing the sense of embodiment towards avatars in virtual reality&amp;rdquo;&lt;/p>
&lt;p>Résumé : Le terme “avatar” fait référence à la représentation des utilisateurs dans un monde virtuel, dans le cas où ils portent un casque de réalité virtuelle et ne peuvent donc pas voir leur propre corps. Les avatars sont désormais devenus une exigence majeure dans les applications de réalité virtuelle immersive, ce qui accroît la nécessité de mieux comprendre et identifier les facteurs qui influencent le sentiment d’incarnation d’un utilisateur envers son avatar. Dans cette thèse, nous avons défini trois axes de recherche pour explorer l’influence de plusieurs facteurs sur le sentiment d’incarnation, en nous basant sur une catégorisation qui ne prend pas seulement en compte les facteurs liés à l’avatar, mais aussi les facteurs liés à l’environnement virtuel et à l’utilisateur. En premier lieu, nous avons étudié l’influence des environnements virtuels partagés sur le sentiment d’incarnation, dans une étude où les utilisateurs accomplissaient une tâche ensemble dans le même environnement virtuel, et dans une autre étude où les utilisateurs partageaient le contrôle du même avatar. Dans une deuxième partie, nous avons exploré les interrelations entre les facteurs liés aux avatars qui influencent le sentiment d’incarnation. Enfin, dans une troisième partie, nous avons étudié l’influence des différences individuelles des utilisateurs sur le sentiment d’incarnation.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>12h00 : &lt;strong>Maud Marchal et Domitile Lourdeaux&lt;/strong>
Titre de la présentation : projets européens, recensement des projets européens dans le GT et retour d&amp;rsquo;expérience&lt;/p>
&lt;/li>
&lt;li>
&lt;p>12h30-14h : pause midi&lt;/p>
&lt;/li>
&lt;li>
&lt;p>14h-16h : &lt;strong>atelier ANSES&lt;/strong>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Atelier sur le rapport d’expertise collective relatifs aux effets sanitaires potentiels liés à l&amp;rsquo;exposition aux technologies utilisant la réalité augmentée et la réalité virtuelle réalisé dans le cadre de l&amp;rsquo;ANSES (téléchargeable à &lt;a href="https://www.anses.fr/fr/system/files/AP2017SA0076Ra.pdf" target="_blank" rel="noopener">https://www.anses.fr/fr/system/files/AP2017SA0076Ra.pdf&lt;/a> ). Cet atelier est co-organisé avec la Commission « Réalité Virtuelle, Augmentée et Mixte » de l’Association de la Recherche en Psychologie Ergonomique et Ergonomie (ARPEGE).&lt;/p>
&lt;ul>
&lt;li>
&lt;p>14h : &lt;strong>Présentation du rapport de l&amp;rsquo;ANSES par Jean-Marie Burkhardt&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>14h30-15h30 : &lt;strong>atelier discussion&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>15h30-16h : pause café&lt;/p>
&lt;/li>
&lt;li>
&lt;p>16h-17h : &lt;strong>Atelier prospective&lt;/strong>&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>Journées Françaises de l'Informatique Graphique</title><link>https://gdr-igrv.fr/event/jfig2021/</link><pubDate>Wed, 24 Nov 2021 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/jfig2021/</guid><description/></item><item><title>Journées inter-GdR CNRS MAGIS-MADICS-IGRV</title><link>https://gdr-igrv.fr/event/intergdr-magis-madics-igrv/</link><pubDate>Wed, 24 Nov 2021 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/intergdr-magis-madics-igrv/</guid><description>&lt;hr>
&lt;pre>&lt;code> Journées inter-GdR CNRS MAGIS-MADICS-IGRV
Observation 3D : outils et verrous
Paris, 24 et 25 novembre 2021
&lt;/code>&lt;/pre>
&lt;hr>
&lt;h1 id="programme-des-journées-">Programme des journées :&lt;/h1>
&lt;p>Mercredi 24 Novembre : de l’acquisition à la représentation de données 3D&lt;/p>
&lt;p>Matin :&lt;/p>
&lt;ul>
&lt;li>9h45-10h : Accueil des participants&lt;/li>
&lt;li>10h-10h15 : Introduction de la journée&lt;/li>
&lt;li>10h15-11h15 : exposé “La 3D au CNES : le système CO3D et quelques applications spatiales avec Pléiades”, Laurent Lebegue et Jean-Marc Delvit, CNES) - 45’ + 15’ questions&lt;/li>
&lt;li>11h15-12h15 : exposé “Deep learning pour les données 3D en télédétection”, Loïc Landrieu, LASTIG - 45’ + 15’ questions&lt;/li>
&lt;li>12h15-12h30 : discussions&lt;/li>
&lt;/ul>
&lt;p>Après midi :&lt;/p>
&lt;ul>
&lt;li>14h : session interactive d’échanges entre participants : chaque participant devra fournir un transparent de présentation de sa thématique / problématique selon une trame qui sera précisée par les organisateurs.&lt;/li>
&lt;li>15h30-16h : pause café&lt;/li>
&lt;li>16h-18h : TP “Deep Learning for 3D Data: Semantic Segmentation of Aerial LiDAR with PointNet”, par Loïc Landrieu, LASTIG.
Note: afin de préparer ce TP, il vous sera demandé de compléter un auto-test&lt;/li>
&lt;/ul>
&lt;hr>
&lt;p>Jeudi 25 Novembre : traiter, annoter et visualiser des données 3D&lt;/p>
&lt;p>Matin :&lt;/p>
&lt;ul>
&lt;li>9h-9h15 : Accueil des participants&lt;/li>
&lt;li>9h15-9h30 : Introduction de la journée&lt;/li>
&lt;li>9h30-10h30 : Mathieu Brédif - LASTIG, Université Gustave Eiffel, IGN-ENSG - “Navigation immersive dans des images historiques (ANR ALEGORIA)” - 45’ + 15’ questions -&lt;/li>
&lt;li>10h30-10h45 : pause café&lt;/li>
&lt;li>10h45-11h45 : Livio de Luca - UMR MAP, CNRS (en Visio) - “Enrichissement sémantique de ressources documentaires spatialisées pour l’étude pluridisciplinaire de Notre-Dame de Paris” - 45’ + 15’ questions.&lt;/li>
&lt;li>11h45-12h15: discussions sur les défis et besoins&lt;/li>
&lt;/ul>
&lt;p>Après midi :&lt;/p>
&lt;ul>
&lt;li>14h-16h : TP iTowns&lt;/li>
&lt;li>16h-16h30 : Conclusion des deux journées (organisateurs)&lt;/li>
&lt;/ul>
&lt;h1 id="date-et-lieu-">Date et lieu :&lt;/h1>
&lt;ul>
&lt;li>Géoroom IGN, 8 Avenue Pasteur, 94160 Saint-Mandé: Métro Saint-Mandé (Ligne 1) ou RER Vincennes (RER A).&lt;/li>
&lt;li>Mercredi 24 et Jeudi 25 novembre 2021 (de 10h le mercredi à 16h30 le jeudi)&lt;/li>
&lt;/ul>
&lt;h1 id="participation-">Participation :&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>Inscription gratuite mais obligatoire avant le 01/11/2021 (nombre de places limité) : envoyer un email à &lt;a href="mailto:gdr.madics-magis-igrv.observation3d@inria.fr">gdr.madics-magis-igrv.observation3d@inria.fr&lt;/a> en précisant votre nom, prénom, laboratoire, jours de présence, thématique de recherche, thématique(s) d&amp;rsquo;intérêt(s) spécifiques sur ces journées&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Attention, en fonction des règles sanitaires et du nombre d’invités, un pass sanitaire pourra être demandé à votre arrivée.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Si le temps le permet, une présentation de 5 minutes de vos travaux pourra être envisagée (session interactive du 24/11 après-midi). Dans ce cas, merci de préciser votre souhait de présenter lors de votre inscription, avec un titre.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h1 id="organisation-">Organisation :&lt;/h1>
&lt;ul>
&lt;li>
&lt;p>Ces journées sont co-organisées par les actions “Analyse d’images pour le suivi des milieux” (P. Dusseux, P.-A. Herrault, A. Puissant, D. Sheeren) et “Données 3D géospatiales” (M. Servières, S. Christophe) du GdR CNRS MAGIS, et par l’action MACLEAN du GdR CNRS MADICS. (T. Corpetti, D. Ienco, R. Interdonato, S. Lefèvre, M.-T. Pham) en partenariat avec le GdR CNRS IG-RV (G. Gesquière).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Contact : &lt;a href="mailto:gdr.madics-magis-igrv.observation3d@inria.fr">gdr.madics-magis-igrv.observation3d@inria.fr&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Les repas de midi des mercredi 24/11 et jeudi 25/11 seront pris en charge par les GdR impliqués&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>Journées du GT GDMM</title><link>https://gdr-igrv.fr/event/gdmm2021/</link><pubDate>Mon, 15 Nov 2021 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/gdmm2021/</guid><description/></item><item><title>Journée « Avatars » 2021</title><link>https://gdr-igrv.fr/event/avatars-2021/</link><pubDate>Wed, 13 Oct 2021 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/avatars-2021/</guid><description/></item><item><title>Explication des modèles des réseaux profonds en problèmes de classification, d'amélioration et d’interprétation des images et des signaux/données (GdR ISIS, GdR IG-RV)</title><link>https://gdr-igrv.fr/event/explicationia/</link><pubDate>Mon, 11 Oct 2021 10:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/explicationia/</guid><description>&lt;p>L&amp;rsquo;apprentissage profond, un des outils-phares de l&amp;rsquo;Intelligence Artificielle, a remporté un grand succès dans de nombreux domaines en traitement et analyse des images, des vidéos, de l&amp;rsquo;information multimodale. Cependant, l&amp;rsquo;aspect boîte noire des réseaux de neurones profonds est devenu l&amp;rsquo;un des principaux obstacles à leur large acceptation dans des applications critiques telles que le diagnostic médical et la thérapie, voire la conduite autonome. Au lieu de développer et d&amp;rsquo;utiliser les réseaux de neurones profonds comme des boîtes noires et d&amp;rsquo;adapter des architectures connues à une variété de problèmes, le but de l&amp;rsquo;apprentissage profond explicable est de proposer des méthodes pour &amp;ldquo;comprendre&amp;rdquo; et &amp;ldquo;expliquer&amp;rdquo; comment ces systèmes produisent leurs décisions. L’explication des décisions des réseaux profonds comporte deux aspects: l’analyse des décisions et la présentation des explications à l’utilisateur. Elle fait donc intervenir deux communautés scientifiques Intelligence artificielle/Image et Visualisation de l’information. L&amp;rsquo;objectif de cette deuxième journée du GDR-ISIS est de rassembler la communauté des chercheurs qui travaillent sur la question de l&amp;rsquo;amélioration de l&amp;rsquo;explicabilité des algorithmes et systèmes d&amp;rsquo;IA dans le domaine image-signal et de visualisation de l’information.&lt;/p>
&lt;p>Les principaux sujets que nous proposons de traiter sont les suivants mais peuvent être étendus :&lt;/p>
&lt;ul>
&lt;li>explication des caractéristiques générées par des couches de convolution des réseaux profonds convolutionnels,&lt;/li>
&lt;li>les mécanismes d&amp;rsquo;attention dans les réseaux neuronaux profonds et leur explication ;&lt;/li>
&lt;li>pour les données temporelles, l&amp;rsquo;explication des caractéristiques et des moments les plus importants pour la prédiction et des intervalles de temps où la contribution de chaque donnée est importante ;&lt;/li>
&lt;li>comment l&amp;rsquo;explication peut aider à rendre les architectures d&amp;rsquo;apprentissage profond plus parcimonieuses et plus légères ;&lt;/li>
&lt;li>lors de l&amp;rsquo;utilisation de données multimodales, comment les prédictions dans les flux de données sont corrélées et s&amp;rsquo;expliquent entre elles ;&lt;/li>
&lt;li>la génération automatique d&amp;rsquo;explications / justifications des décisions des algorithmes et des systèmes ;&lt;/li>
&lt;li>visualisation des explications de manière interprétable pour les utilisateurs;&lt;/li>
&lt;li>évaluation des explications générées par l&amp;rsquo;apprentissage profond et d&amp;rsquo;autres systèmes d&amp;rsquo;IA:&lt;/li>
&lt;/ul>
&lt;p>Cette journée est organisée conjointement par le thème B Image et vision et le thème T conjointement avec GDR IGRV . Le programme comporte 2 conférences invitées :&lt;/p>
&lt;p>“Une analyse théorique de la méthode LIME”, Damien Garreau, Laboratoire J.A. Dieudonné UMR CNRS 7351 Université de Nice Côte d’Azur
&amp;ldquo;Reasoning vs. bias exploitation: X-raying high-capacity deep networks&amp;rdquo; Chrisian Wolf, LIRIS UMR 5205, INSA Lyon&lt;/p>
&lt;p>Organisateurs :&lt;/p>
&lt;p>GDR-ISIS&lt;/p>
&lt;p>Nicolas Thome : &lt;a href="mailto:nicolas.thome@cnam.fr">nicolas.thome@cnam.fr&lt;/a>
Jenny Benois-Pineau : &lt;a href="mailto:jenny.benois-pineau@u-bordeaux.fr">jenny.benois-pineau@u-bordeaux.fr&lt;/a>
Alexandre Benoit : &lt;a href="mailto:alexandre.benoit@univ-smb.fr">alexandre.benoit@univ-smb.fr&lt;/a>&lt;/p>
&lt;p>GDR-IGRV&lt;/p>
&lt;p>Romain Vuillemot : &lt;a href="mailto:romain.vuillemot@ec-lyon.fr">romain.vuillemot@ec-lyon.fr&lt;/a>
Romain Bourqui : &lt;a href="mailto:romain.bourqui@u-bordeaux.fr">romain.bourqui@u-bordeaux.fr&lt;/a>&lt;/p>
&lt;p>Propositions des exposés sont à envoyer aux organisateurs de la journée.&lt;/p></description></item><item><title>Journées du GTAS</title><link>https://gdr-igrv.fr/event/gtas-2021/</link><pubDate>Mon, 05 Jul 2021 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/gtas-2021/</guid><description/></item></channel></rss>