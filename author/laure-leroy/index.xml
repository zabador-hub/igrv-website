<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Laure Leroy | GdR IG-RV</title><link>https://gdr-igrv.fr/author/laure-leroy/</link><atom:link href="https://gdr-igrv.fr/author/laure-leroy/index.xml" rel="self" type="application/rss+xml"/><description>Laure Leroy</description><generator>Wowchemy (https://wowchemy.com)</generator><language>fr-fr</language><image><url>https://gdr-igrv.fr/author/laure-leroy/avatar_hu6c724d8448d979fdf37acd4434833548_8457349_270x270_fill_lanczos_center_3.png</url><title>Laure Leroy</title><link>https://gdr-igrv.fr/author/laure-leroy/</link></image><item><title>Journée « Environnements virtuels : adaptation du système à l'humain ou de l'humain au système ? »</title><link>https://gdr-igrv.fr/event/journee_gtrv2022/</link><pubDate>Wed, 09 Mar 2022 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee_gtrv2022/</guid><description>&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img src="https://journee-rvia.hds.utc.fr/_detail/pma_equipe_copyright.jpg?id=fr%3Astart" alt="" loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h1 id="responsables">Responsables&lt;/h1>
&lt;ul>
&lt;li>Domitile Lourdeaux (Heudiasyc – Université de technologie de Compiègne)&lt;/li>
&lt;li>Indira Thouvenin-Moutapa (Heudiasyc – Université de technologie de Compiègne)&lt;/li>
&lt;/ul>
&lt;h1 id="programme">Programme&lt;/h1>
&lt;p>&lt;strong>9 mars 2022&lt;/strong>&lt;/p>
&lt;p>Le programme prévisionnel de la journée est le suivant :&lt;/p>
&lt;p>Train de Paris : départ 8.34 - arrivée 9.26 Comptez 10 min pour rejoindre le centre d’innovation en taxi. Les bus sont gratuits mais lents (prévoir 30 min). Voir plan d&amp;rsquo;accès Centre d&amp;rsquo;Innovation à côté du Génie Informatique.&lt;/p>
&lt;p>Le programme sera détaillé ultérieurement, voici les grands temps forts :&lt;/p>
&lt;ul>
&lt;li>9.30-10.00 Accueil, café&lt;/li>
&lt;li>10.10-10.15 Ouverture (Mot de l’AFIA, du GdR IG-RV et de Philippe Bonnifait, directeur de l&amp;rsquo;UMR 7253 Heudiasyc)&lt;/li>
&lt;li>10.15-10.35 « Pourquoi cette journée ? Environnements virtuels : adaptation du système à l&amp;rsquo;humain ou de l&amp;rsquo;humain au système ? » Domitile Lourdeaux et Indira Thouvenin&lt;/li>
&lt;li>10.35-11.05 Présentation invitée « Environnements virtuels et modèles de décision pour l’interaction » IRISA, Rennes&lt;/li>
&lt;li>11.05-11.15 Pause café&lt;/li>
&lt;li>11.15-11.45 Présentation invitée « La réalité virtuelle en tant qu&amp;rsquo;outil de formation adapté aux pratiques de l&amp;rsquo;enseignant: scénarisation des travaux pratiques, enseignement du geste et adaptation au comportement » Ludovic Hamon, LIUM, Laval&lt;/li>
&lt;li>11.45-12.10 « Facteurs humains et réalité virtuelle : détecter les effets secondaires avec capteurs physiologiques et machine learning » Alexis Souchet, Heudiasyc Compiègne&lt;/li>
&lt;li>12.10-12.30 « Génération d’un profil dynamique du stress pour l’entraînement à la gestion de situations de crise » Luca Pelissero-Witoslawski, Heudiasyc Compiègne&lt;/li>
&lt;li>12.30-14.00 Buffet et session Posters&lt;/li>
&lt;li>14.00-15.00 Visite du CAVE et des démonstrations&lt;/li>
&lt;li>15.00-15.30 Présentation invitée « Les agents virtuels dans les environnements immersifs d&amp;rsquo;apprentissage » David Panzoli, IRIT Toulouse&lt;/li>
&lt;li>15.30-15.55 « Toucher social pour l’interaction humain-agent incarné en environnement virtuel » Fabien Boucaud, ISIR, Paris&lt;/li>
&lt;li>15.55-16.15 « Retours adaptatif en réalité augmentée basés sur l’état du conducteur de véhicule hautement automatisé lors de la reprise de contrôle » Baptiste Wojtkowski, Heudiasyc, Compiègne&lt;/li>
&lt;li>16.15-17.00 Table Ronde « Environnements virtuels : adaptation du système à l&amp;rsquo;humain ou de l&amp;rsquo;humain au système ? »&lt;/li>
&lt;/ul>
&lt;p>Un mode hybride est en cours d&amp;rsquo;études mais on privilégie le présentiel pour permettre de participer aux démonstrations.&lt;/p>
&lt;p>Train retour départ 17.35 – arrivée 18.26&lt;/p>
&lt;h1 id="inscriptions">Inscriptions&lt;/h1>
&lt;p>Pour des raisons pratiques, les inscriptions devront se faire avant le 28 février 2022&lt;/p>
&lt;p>&lt;a href="https://journee-rvia.hds.utc.fr/fr/inscriptions" target="_blank" rel="noopener">https://journee-rvia.hds.utc.fr/fr/inscriptions&lt;/a>&lt;/p>
&lt;p>Retrouvez toutes les informations&lt;/p>
&lt;p>&lt;a href="https://journee-rvia.hds.utc.fr/fr/presentation" target="_blank" rel="noopener">https://journee-rvia.hds.utc.fr/fr/presentation&lt;/a>&lt;/p></description></item><item><title>Journée du GT-RV</title><link>https://gdr-igrv.fr/event/journee_gtrv2022-8-03/</link><pubDate>Tue, 08 Mar 2022 09:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/event/journee_gtrv2022-8-03/</guid><description>&lt;p>Comme vous le savez déjà, la journée du GT-RV se tiendra le 8 mars dans les locaux parisiens de l&amp;rsquo;UTC au 62 Boulevard de Sébastopol, 75003 Paris&lt;/p>
&lt;p>Nous vous proposons de vous inscrire à l&amp;rsquo;adresse suivante en indiquant si vous souhaitez être en présentiel ou éventuellement distanciel.
&lt;a href="https://framaforms.org/inscription-journees-du-gt-rv-1644410184" target="_blank" rel="noopener">https://framaforms.org/inscription-journees-du-gt-rv-1644410184&lt;/a>&lt;/p>
&lt;p>L&amp;rsquo;entrée est gratuite, mais le présentiel est limité à 40 personnes.&lt;/p>
&lt;p>Attention, pour des raisons sanitaires, nous ne pouvons pas vous proposer de repas de déjeuner sur place, mais nous avons le plaisir d&amp;rsquo;être accueillis dans un des quartiers parisiens les plus fournis en petits restaurants très sympathiques.&lt;/p>
&lt;p>Le distanciel se fera à cette adresse :
&lt;a href="https://catalogue-ent2.univ-paris8.fr/BigBlueButtonReunion/client.php?meetingID=4882&amp;amp;fullName=Anonyme&amp;amp;password=4bsexESkl7D092oXV_v5jRQKHh6imPyZMpwa&amp;amp;checksum=b1e8eb8c7ad246eb8689dc2f89ed2fb0ecb063bc" target="_blank" rel="noopener">https://catalogue-ent2.univ-paris8.fr/BigBlueButtonReunion/client.php?meetingID=4882&amp;fullName=Anonyme&amp;password=4bsexESkl7D092oXV_v5jRQKHh6imPyZMpwa&amp;checksum=b1e8eb8c7ad246eb8689dc2f89ed2fb0ecb063bc&lt;/a>&lt;/p>
&lt;h1 id="programme">Programme&lt;/h1>
&lt;p>Nous sommes heureux de vous proposer le programme de la journée, que vous pourrez retrouver, pour plus de facilité en pdf attaché en pièce jointe :
9h30-11h00 : Présentations, Chairman : Pr Daniel Mestre&lt;/p>
&lt;ul>
&lt;li>9h 30: &lt;strong>RAMOUSSE Florian&lt;/strong>
Laboratoire / Institution : LIRIS / École Centrale de Lyon&lt;/li>
&lt;/ul>
&lt;p>Titre de la présentation : Immersive environnements for Assessing and Treating Binge Eating Disorders : How the Visual Quality of 3D Food Stimuli can Influence the Desire to Eat&lt;/p>
&lt;ul>
&lt;li>9h50 : &lt;strong>VILLENAVE Sophie&lt;/strong>
Laboratoire / Institution : LIRIS / École Centrale de Lyon-ENISE&lt;/li>
&lt;/ul>
&lt;p>Titre de la présentation : XREcho : Un outil d’enregistrement et de visualisation des expériences XR
Résumé : XREcho, c&amp;rsquo;est un plugin pour le logiciel Unity qui permet d&amp;rsquo;enregistrer et de rejouer en temps réel des sessions d&amp;rsquo;XR (VR et AR), développées avec Unity.
Le développement du plugin est en cours, mais nous sommes en train de rédiger un papier destiné à MMSys pour la section demo/soft/dataset afin d&amp;rsquo;avoir accès à une plateforme de diffusion large.
Ce plugin devrait permettre à la communauté scientifique étudiant le comportement et les interactions des utilisateurs avec l&amp;rsquo;AR et la VR d&amp;rsquo;obtenir des données objectives afin d&amp;rsquo;établir des modèles plus justes et plus proche de la réalité.&lt;/p>
&lt;ul>
&lt;li>10h10 : &lt;strong>Elodie Bayle&lt;/strong>
Laboratoire : Institut de recherche biomédicale des armées&lt;/li>
&lt;/ul>
&lt;p>Titre de la présentation : Entre fusion et rivalité binoculaires : Impact des caractéristiques des stimuli visuels lors de l’utilisation d’un système de réalité augmentée semi-transparent monoculaire.
Résumé : Les visuels de casque monoculaires utilisés dans l’aéronautique augmentent la vision des pilotes et facilitent l’accès aux informations essentielles telles que la symbologie de vol. Du fait de la projection d’une image virtuelle devant un seul œil alors que l’environnement est binoculaire, cela génère une perception visuelle particulière. Le travail de cette thèse consistait à évaluer l’impact des caractéristiques des stimuli sur les performances à travers deux études psychophysiques et une étude écologique en simulateur de vol.&lt;/p>
&lt;ul>
&lt;li>10h30 : &lt;strong>Olivier ROUPIN&lt;/strong>
Laboratoire : Lab-STICC / InterDigital &amp;amp; IMT Atlantique Brest&lt;/li>
&lt;/ul>
&lt;p>Titre de la présentation : Détection d’objets supprimés dans des scènes 3D à l&amp;rsquo;aide d&amp;rsquo;images dans les applications de Réalité Mixte
Résumé : Une connaissance précise de l&amp;rsquo;environnement est requise pour l&amp;rsquo;interaction entre contenu virtuel et réel en réalité mixte. Cependant, une mise à jour en temps réel du modèle de la réalité est coûteuse en temps et matériel; diverses approches hybrides ont donc été développées : un modèle à jour du monde peut être déduit d&amp;rsquo;une capture hors-ligne de l&amp;rsquo;environnement 3D, corrigé en ligne en utilisant une séquence d&amp;rsquo;images courantes, à condition qu&amp;rsquo;un algorithme de détection de changement rapide et robuste soit développé. Les algorithmes existant présente un biais vers la détection d&amp;rsquo;apparition d&amp;rsquo;objets au mépris de la suppression d&amp;rsquo;objets; dans un environnement où l&amp;rsquo;arrière plan est photométriquement uniforme, la disparition d&amp;rsquo;objets au premier plan, entre un scan 3D d&amp;rsquo;une scène et la prise de nouvelles photos de cette même scène, est difficile à détecter par re-projection. Notre approche contourne ce problème en se concentrant sur les régions occultées par le premier plan où aucun changement ne se produit après re-projection. On montre par l&amp;rsquo;expérience sur des dataset réalistes, que cette approche est meilleure à la tâche de détection et localisation 3D d&amp;rsquo;objets supprimés. Cette approche peut être combinée avec un algorithme de détection d&amp;rsquo;apparitions d&amp;rsquo;objets pour produire un système de détection de changement complet.&lt;/p>
&lt;ul>
&lt;li>10h50 : &lt;strong>Charlotte DUBOSC&lt;/strong>
Laboratoire : Présence &amp;amp; Innovation, LAMPA / ENSAM Laval&lt;/li>
&lt;/ul>
&lt;p>Titre de la présentation : Étude de l’interdépendance du réalisme visuel et comportemental pour l’acceptation des personnages virtuels en environnement immersif collaboratif
Résumé : Présentation du protocole et des développements d’une expérimentation de thèse portant sur l’interdépendance du réalisme visuel et comportemental de personnages virtuels. Cette étude ambitionne d’évaluer la tolérance des utilisateurs confrontés à des personnages dont l’apparence présente des inadéquations potentielles avec leur expressivité faciale. Les évaluations porteront sur le réalisme perçu, la familiarité, l’étrangeté et l’attractivité des agents virtuels.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>11h10-11h30 pause&lt;/p>
&lt;/li>
&lt;li>
&lt;p>11h30-12h30 : &lt;strong>Présentations&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>11h30 : &lt;strong>Rebecca Fribourg&lt;/strong> (École Centrale de Nantes) — Prix de thèse IG-RV 2021&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Titre de la présentation : &amp;ldquo;Contribution to the study of factors influencing the sense of embodiment towards avatars in virtual reality&amp;rdquo;&lt;/p>
&lt;p>Résumé : Le terme “avatar” fait référence à la représentation des utilisateurs dans un monde virtuel, dans le cas où ils portent un casque de réalité virtuelle et ne peuvent donc pas voir leur propre corps. Les avatars sont désormais devenus une exigence majeure dans les applications de réalité virtuelle immersive, ce qui accroît la nécessité de mieux comprendre et identifier les facteurs qui influencent le sentiment d’incarnation d’un utilisateur envers son avatar. Dans cette thèse, nous avons défini trois axes de recherche pour explorer l’influence de plusieurs facteurs sur le sentiment d’incarnation, en nous basant sur une catégorisation qui ne prend pas seulement en compte les facteurs liés à l’avatar, mais aussi les facteurs liés à l’environnement virtuel et à l’utilisateur. En premier lieu, nous avons étudié l’influence des environnements virtuels partagés sur le sentiment d’incarnation, dans une étude où les utilisateurs accomplissaient une tâche ensemble dans le même environnement virtuel, et dans une autre étude où les utilisateurs partageaient le contrôle du même avatar. Dans une deuxième partie, nous avons exploré les interrelations entre les facteurs liés aux avatars qui influencent le sentiment d’incarnation. Enfin, dans une troisième partie, nous avons étudié l’influence des différences individuelles des utilisateurs sur le sentiment d’incarnation.&lt;/p>
&lt;ul>
&lt;li>
&lt;p>12h00 : &lt;strong>Maud Marchal et Domitile Lourdeaux&lt;/strong>
Titre de la présentation : projets européens, recensement des projets européens dans le GT et retour d&amp;rsquo;expérience&lt;/p>
&lt;/li>
&lt;li>
&lt;p>12h30-14h : pause midi&lt;/p>
&lt;/li>
&lt;li>
&lt;p>14h-16h : &lt;strong>atelier ANSES&lt;/strong>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>Atelier sur le rapport d’expertise collective relatifs aux effets sanitaires potentiels liés à l&amp;rsquo;exposition aux technologies utilisant la réalité augmentée et la réalité virtuelle réalisé dans le cadre de l&amp;rsquo;ANSES (téléchargeable à &lt;a href="https://www.anses.fr/fr/system/files/AP2017SA0076Ra.pdf" target="_blank" rel="noopener">https://www.anses.fr/fr/system/files/AP2017SA0076Ra.pdf&lt;/a> ). Cet atelier est co-organisé avec la Commission « Réalité Virtuelle, Augmentée et Mixte » de l’Association de la Recherche en Psychologie Ergonomique et Ergonomie (ARPEGE).&lt;/p>
&lt;ul>
&lt;li>
&lt;p>14h : &lt;strong>Présentation du rapport de l&amp;rsquo;ANSES par Jean-Marie Burkhardt&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>14h30-15h30 : &lt;strong>atelier discussion&lt;/strong>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>15h30-16h : pause café&lt;/p>
&lt;/li>
&lt;li>
&lt;p>16h-17h : &lt;strong>Atelier prospective&lt;/strong>&lt;/p>
&lt;/li>
&lt;/ul></description></item><item><title>Groupe de travail "Réalités virtuelles" (GT-RV)</title><link>https://gdr-igrv.fr/gts/gt-rv/</link><pubDate>Mon, 21 Jun 2021 00:00:00 +0000</pubDate><guid>https://gdr-igrv.fr/gts/gt-rv/</guid><description>&lt;img src="photo gtrv.png" height="300">
&lt;ul>
&lt;li>&lt;strong>Responsables&lt;/strong> : Pierre Chevaillier (Lab-STICC/CERV, ENIB,
Brest), Laure Leroy (Paragraphe, univ. Paris 8 / IRBA).&lt;/li>
&lt;li>&lt;strong>Mots-clés&lt;/strong> : réalité virtuelle, réalité augmentée, interaction 3D, métaphores, interfaces, multi-modalité,
perception, cognition, motricité, comportement, immersion, présence, usages, acceptabilité.&lt;/li>
&lt;/ul>
&lt;p>Le thème générique des modèles et techniques d’interaction en environnement virtuel, que ce soit
dans un contexte de réalité virtuelle ou dans un contexte de réalité augmentée est central pour ce
groupe de travail. La problématique de l’immersion et de l’interaction est abordée à la fois sous un
angle technologique, essentiellement informatique, et d’un point de vue humano-centré. Malgré les
très nombreux travaux scientifiques et les améliorations constantes des dispositifs techniques,
l’interaction en environnement 3D reste un sujet d’actualité qui est très loin d’être clos, car il reste
encore aujourd’hui difficile pour un sujet humain d’interagir avec un tel environnement. Le cœur
scientifique de ce groupe de travail est la prise en compte les situations d&amp;rsquo;interaction d&amp;rsquo;un sujet humain
avec un environnement de synthèse dans lequel il se trouve immergé, que ce soit dans un contexte de
réalité virtuelle ou dans un contexte de réalité augmentée. L&amp;rsquo;objet d&amp;rsquo;étude est le couplage perceptivo-
moteur et cognitif entre l&amp;rsquo;utilisateur et l&amp;rsquo;environnement. La question est donc abordée selon le
triptyque : (1) tâche (action à réaliser dans l’environnement), (2) dispositif, à la fois logiciel (mise en
évidence d’une métaphore d’interaction) et matériel (dispositif d’interaction) et (3) expérience vécue
par le sujet humain.&lt;/p>
&lt;p>Les nouvelles générations de dispositifs immersifs, visiocasques, lunettes de réalité augmentée, ou
l’extension de leurs usages, soulèvent des questions sur leur acceptabilité, la nécessité d’une
conception spécifique des environnements virtuels et des interfaces 3D, ou les limites des capacités
d’adaptation des sujets humains à leur utilisation. Ces questions sont d’autant plus pertinentes que la
réalité virtuelle ou augmentée est peut-être en passe de sortir d’un usage limité dans le temps, la
nature des tâches et le profil des utilisateurs, pour investir des usages destinés à un public plus vaste
(enfants, adultes, personnes âgées), pour des usages variés (ludiques, éducatifs, médicaux, etc.). Ce
nouveau contexte motive que la communauté scientifique dresse un état des connaissances sur le
36domaine et s’interroge sur les nouvelles études à mener. Par exemple, on peut s’interroger sur l’impact
du type de dispositif sur la perception des distances, du mouvement, la précision des gestes, la
locomotion, la perception de soi… Est-ce que les avancées technologiques font que les dispositifs ont
des caractéristiques techniques garantissant une immersion de qualité (selon quels critères) ? Est-ce
que les valeurs critiques des différents critères d’acceptabilité sont les mêmes ? Que sait-on de
l’impact de leurs caractéristiques sur les processus physiologiques et cognitifs ? Existe-t-il des risques
connus, potentiels, en matière de santé publique ? Est-il envisageable de définir des guides de
conception des environnements virtuels adaptés à ces nouveaux contextes ?&lt;/p></description></item></channel></rss>